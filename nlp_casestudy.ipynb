{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sunilreddyj/nlp-unified-analysis/blob/main/nlp_casestudy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "id": "e74612de",
        "outputId": "f4ea7a18-73df-4bf3-ded0-1409af590d8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/sumitm004/arxiv-scientific-research-papers-dataset?dataset_version_number=2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 62.4M/62.4M [00:03<00:00, 16.5MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['id', 'title', 'category', 'category_code', 'published_date',\n",
            "       'updated_date', 'authors', 'first_author', 'summary',\n",
            "       'summary_word_count'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "             id                                              title  \\\n",
              "0  cs-9308101v1                               Dynamic Backtracking   \n",
              "1  cs-9308102v1  A Market-Oriented Programming Environment and ...   \n",
              "2  cs-9309101v1            An Empirical Analysis of Search in GSAT   \n",
              "3  cs-9311101v1  The Difficulties of Learning Logic Programs wi...   \n",
              "4  cs-9311102v1  Software Agents: Completing Patterns and Const...   \n",
              "\n",
              "                  category category_code published_date updated_date  \\\n",
              "0  Artificial Intelligence         cs.AI         8/1/93       8/1/93   \n",
              "1  Artificial Intelligence         cs.AI         8/1/93       8/1/93   \n",
              "2  Artificial Intelligence         cs.AI         9/1/93       9/1/93   \n",
              "3  Artificial Intelligence         cs.AI        11/1/93      11/1/93   \n",
              "4  Artificial Intelligence         cs.AI        11/1/93      11/1/93   \n",
              "\n",
              "                                          authors       first_author  \\\n",
              "0                              ['M. L. Ginsberg']   'M. L. Ginsberg'   \n",
              "1                               ['M. P. Wellman']    'M. P. Wellman'   \n",
              "2                      ['I. P. Gent', 'T. Walsh']       'I. P. Gent'   \n",
              "3  ['F. Bergadano', 'D. Gunetti', 'U. Trinchero']     'F. Bergadano'   \n",
              "4            ['J. C. Schlimmer', 'L. A. Hermens']  'J. C. Schlimmer'   \n",
              "\n",
              "                                             summary  summary_word_count  \\\n",
              "0  Because of their occasional need to return to ...                  79   \n",
              "1  Market price systems constitute a well-underst...                 119   \n",
              "2  We describe an extensive study of search in GS...                 167   \n",
              "3  As real logic programmers normally use cut (!)...                 174   \n",
              "4  To support the goal of allowing users to recor...                 187   \n",
              "\n",
              "                                       title_cleaned  \\\n",
              "0                               dynamic backtracking   \n",
              "1  a marketoriented programming environment and i...   \n",
              "2            an empirical analysis of search in gsat   \n",
              "3  the difficulties of learning logic programs wi...   \n",
              "4  software agents completing patterns and constr...   \n",
              "\n",
              "                                     summary_cleaned  \\\n",
              "0  because of their occasional need to return to ...   \n",
              "1  market price systems constitute a wellundersto...   \n",
              "2  we describe an extensive study of search in gs...   \n",
              "3  as real logic programmers normally use cut  an...   \n",
              "4  to support the goal of allowing users to recor...   \n",
              "\n",
              "                                        title_tokens  \\\n",
              "0                            [dynamic, backtracking]   \n",
              "1  [a, marketoriented, programming, environment, ...   \n",
              "2    [an, empirical, analysis, of, search, in, gsat]   \n",
              "3  [the, difficulties, of, learning, logic, progr...   \n",
              "4  [software, agents, completing, patterns, and, ...   \n",
              "\n",
              "                                      summary_tokens  \\\n",
              "0  [because, of, their, occasional, need, to, ret...   \n",
              "1  [market, price, systems, constitute, a, wellun...   \n",
              "2  [we, describe, an, extensive, study, of, searc...   \n",
              "3  [as, real, logic, programmers, normally, use, ...   \n",
              "4  [to, support, the, goal, of, allowing, users, ...   \n",
              "\n",
              "                           title_tokens_no_stopwords  \\\n",
              "0                            [dynamic, backtracking]   \n",
              "1  [marketoriented, programming, environment, app...   \n",
              "2                [empirical, analysis, search, gsat]   \n",
              "3     [difficulties, learning, logic, programs, cut]   \n",
              "4  [software, agents, completing, patterns, const...   \n",
              "\n",
              "                         summary_tokens_no_stopwords  \\\n",
              "0  [occasional, need, return, shallow, points, se...   \n",
              "1  [market, price, systems, constitute, wellunder...   \n",
              "2  [describe, extensive, study, search, gsat, app...   \n",
              "3  [real, logic, programmers, normally, use, cut,...   \n",
              "4  [support, goal, allowing, users, record, retri...   \n",
              "\n",
              "                                       title_stemmed  \\\n",
              "0                                 [dynam, backtrack]   \n",
              "1  [marketori, program, environ, applic, distribu...   \n",
              "2                     [empir, analysi, search, gsat]   \n",
              "3           [difficulti, learn, logic, program, cut]   \n",
              "4  [softwar, agent, complet, pattern, construct, ...   \n",
              "\n",
              "                                     summary_stemmed  \\\n",
              "0  [occasion, need, return, shallow, point, searc...   \n",
              "1  [market, price, system, constitut, wellunderst...   \n",
              "2  [describ, extens, studi, search, gsat, approxi...   \n",
              "3  [real, logic, programm, normal, use, cut, effe...   \n",
              "4  [support, goal, allow, user, record, retriev, ...   \n",
              "\n",
              "                                   preprocessed_text  \\\n",
              "0  [dynam, backtrack, occasion, need, return, sha...   \n",
              "1  [marketori, program, environ, applic, distribu...   \n",
              "2  [empir, analysi, search, gsat, describ, extens...   \n",
              "3  [difficulti, learn, logic, program, cut, real,...   \n",
              "4  [softwar, agent, complet, pattern, construct, ...   \n",
              "\n",
              "                               preprocessed_text_str  \n",
              "0  dynam backtrack occasion need return shallow p...  \n",
              "1  marketori program environ applic distribut mul...  \n",
              "2  empir analysi search gsat describ extens studi...  \n",
              "3  difficulti learn logic program cut real logic ...  \n",
              "4  softwar agent complet pattern construct user i...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2d2799d9-74d9-4cf9-b04f-d065e5c2dbad\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>category</th>\n",
              "      <th>category_code</th>\n",
              "      <th>published_date</th>\n",
              "      <th>updated_date</th>\n",
              "      <th>authors</th>\n",
              "      <th>first_author</th>\n",
              "      <th>summary</th>\n",
              "      <th>summary_word_count</th>\n",
              "      <th>title_cleaned</th>\n",
              "      <th>summary_cleaned</th>\n",
              "      <th>title_tokens</th>\n",
              "      <th>summary_tokens</th>\n",
              "      <th>title_tokens_no_stopwords</th>\n",
              "      <th>summary_tokens_no_stopwords</th>\n",
              "      <th>title_stemmed</th>\n",
              "      <th>summary_stemmed</th>\n",
              "      <th>preprocessed_text</th>\n",
              "      <th>preprocessed_text_str</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cs-9308101v1</td>\n",
              "      <td>Dynamic Backtracking</td>\n",
              "      <td>Artificial Intelligence</td>\n",
              "      <td>cs.AI</td>\n",
              "      <td>8/1/93</td>\n",
              "      <td>8/1/93</td>\n",
              "      <td>['M. L. Ginsberg']</td>\n",
              "      <td>'M. L. Ginsberg'</td>\n",
              "      <td>Because of their occasional need to return to ...</td>\n",
              "      <td>79</td>\n",
              "      <td>dynamic backtracking</td>\n",
              "      <td>because of their occasional need to return to ...</td>\n",
              "      <td>[dynamic, backtracking]</td>\n",
              "      <td>[because, of, their, occasional, need, to, ret...</td>\n",
              "      <td>[dynamic, backtracking]</td>\n",
              "      <td>[occasional, need, return, shallow, points, se...</td>\n",
              "      <td>[dynam, backtrack]</td>\n",
              "      <td>[occasion, need, return, shallow, point, searc...</td>\n",
              "      <td>[dynam, backtrack, occasion, need, return, sha...</td>\n",
              "      <td>dynam backtrack occasion need return shallow p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cs-9308102v1</td>\n",
              "      <td>A Market-Oriented Programming Environment and ...</td>\n",
              "      <td>Artificial Intelligence</td>\n",
              "      <td>cs.AI</td>\n",
              "      <td>8/1/93</td>\n",
              "      <td>8/1/93</td>\n",
              "      <td>['M. P. Wellman']</td>\n",
              "      <td>'M. P. Wellman'</td>\n",
              "      <td>Market price systems constitute a well-underst...</td>\n",
              "      <td>119</td>\n",
              "      <td>a marketoriented programming environment and i...</td>\n",
              "      <td>market price systems constitute a wellundersto...</td>\n",
              "      <td>[a, marketoriented, programming, environment, ...</td>\n",
              "      <td>[market, price, systems, constitute, a, wellun...</td>\n",
              "      <td>[marketoriented, programming, environment, app...</td>\n",
              "      <td>[market, price, systems, constitute, wellunder...</td>\n",
              "      <td>[marketori, program, environ, applic, distribu...</td>\n",
              "      <td>[market, price, system, constitut, wellunderst...</td>\n",
              "      <td>[marketori, program, environ, applic, distribu...</td>\n",
              "      <td>marketori program environ applic distribut mul...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cs-9309101v1</td>\n",
              "      <td>An Empirical Analysis of Search in GSAT</td>\n",
              "      <td>Artificial Intelligence</td>\n",
              "      <td>cs.AI</td>\n",
              "      <td>9/1/93</td>\n",
              "      <td>9/1/93</td>\n",
              "      <td>['I. P. Gent', 'T. Walsh']</td>\n",
              "      <td>'I. P. Gent'</td>\n",
              "      <td>We describe an extensive study of search in GS...</td>\n",
              "      <td>167</td>\n",
              "      <td>an empirical analysis of search in gsat</td>\n",
              "      <td>we describe an extensive study of search in gs...</td>\n",
              "      <td>[an, empirical, analysis, of, search, in, gsat]</td>\n",
              "      <td>[we, describe, an, extensive, study, of, searc...</td>\n",
              "      <td>[empirical, analysis, search, gsat]</td>\n",
              "      <td>[describe, extensive, study, search, gsat, app...</td>\n",
              "      <td>[empir, analysi, search, gsat]</td>\n",
              "      <td>[describ, extens, studi, search, gsat, approxi...</td>\n",
              "      <td>[empir, analysi, search, gsat, describ, extens...</td>\n",
              "      <td>empir analysi search gsat describ extens studi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>cs-9311101v1</td>\n",
              "      <td>The Difficulties of Learning Logic Programs wi...</td>\n",
              "      <td>Artificial Intelligence</td>\n",
              "      <td>cs.AI</td>\n",
              "      <td>11/1/93</td>\n",
              "      <td>11/1/93</td>\n",
              "      <td>['F. Bergadano', 'D. Gunetti', 'U. Trinchero']</td>\n",
              "      <td>'F. Bergadano'</td>\n",
              "      <td>As real logic programmers normally use cut (!)...</td>\n",
              "      <td>174</td>\n",
              "      <td>the difficulties of learning logic programs wi...</td>\n",
              "      <td>as real logic programmers normally use cut  an...</td>\n",
              "      <td>[the, difficulties, of, learning, logic, progr...</td>\n",
              "      <td>[as, real, logic, programmers, normally, use, ...</td>\n",
              "      <td>[difficulties, learning, logic, programs, cut]</td>\n",
              "      <td>[real, logic, programmers, normally, use, cut,...</td>\n",
              "      <td>[difficulti, learn, logic, program, cut]</td>\n",
              "      <td>[real, logic, programm, normal, use, cut, effe...</td>\n",
              "      <td>[difficulti, learn, logic, program, cut, real,...</td>\n",
              "      <td>difficulti learn logic program cut real logic ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>cs-9311102v1</td>\n",
              "      <td>Software Agents: Completing Patterns and Const...</td>\n",
              "      <td>Artificial Intelligence</td>\n",
              "      <td>cs.AI</td>\n",
              "      <td>11/1/93</td>\n",
              "      <td>11/1/93</td>\n",
              "      <td>['J. C. Schlimmer', 'L. A. Hermens']</td>\n",
              "      <td>'J. C. Schlimmer'</td>\n",
              "      <td>To support the goal of allowing users to recor...</td>\n",
              "      <td>187</td>\n",
              "      <td>software agents completing patterns and constr...</td>\n",
              "      <td>to support the goal of allowing users to recor...</td>\n",
              "      <td>[software, agents, completing, patterns, and, ...</td>\n",
              "      <td>[to, support, the, goal, of, allowing, users, ...</td>\n",
              "      <td>[software, agents, completing, patterns, const...</td>\n",
              "      <td>[support, goal, allowing, users, record, retri...</td>\n",
              "      <td>[softwar, agent, complet, pattern, construct, ...</td>\n",
              "      <td>[support, goal, allow, user, record, retriev, ...</td>\n",
              "      <td>[softwar, agent, complet, pattern, construct, ...</td>\n",
              "      <td>softwar agent complet pattern construct user i...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2d2799d9-74d9-4cf9-b04f-d065e5c2dbad')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2d2799d9-74d9-4cf9-b04f-d065e5c2dbad button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2d2799d9-74d9-4cf9-b04f-d065e5c2dbad');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e0a507d7-c0ed-49bc-a7d3-25795054ce24\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e0a507d7-c0ed-49bc-a7d3-25795054ce24')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e0a507d7-c0ed-49bc-a7d3-25795054ce24 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"cs-9308102v1\",\n          \"cs-9311102v1\",\n          \"cs-9309101v1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"A Market-Oriented Programming Environment and its Application to\\n  Distributed Multicommodity Flow Problems\",\n          \"Software Agents: Completing Patterns and Constructing User Interfaces\",\n          \"An Empirical Analysis of Search in GSAT\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Artificial Intelligence\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category_code\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"cs.AI\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"published_date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"8/1/93\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"updated_date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"8/1/93\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"authors\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"['M. P. Wellman']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"first_author\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"'M. P. Wellman'\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summary\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Market price systems constitute a well-understood class of mechanisms that\\nunder certain conditions provide effective decentralization of decision making\\nwith minimal communication overhead. In a market-oriented programming approach\\nto distributed problem solving, we derive the activities and resource\\nallocations for a set of computational agents by computing the competitive\\nequilibrium of an artificial economy. WALRAS provides basic constructs for\\ndefining computational market structures, and protocols for deriving their\\ncorresponding price equilibria. In a particular realization of this approach\\nfor a form of multicommodity flow problem, we see that careful construction of\\nthe decision process according to economic principles can lead to efficient\\ndistributed resource allocation, and that the behavior of the system can be\\nmeaningfully analyzed in economic terms.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summary_word_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 45,\n        \"min\": 79,\n        \"max\": 187,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          119\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title_cleaned\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"a marketoriented programming environment and its application to\\n  distributed multicommodity flow problems\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summary_cleaned\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"market price systems constitute a wellunderstood class of mechanisms that\\nunder certain conditions provide effective decentralization of decision making\\nwith minimal communication overhead in a marketoriented programming approach\\nto distributed problem solving we derive the activities and resource\\nallocations for a set of computational agents by computing the competitive\\nequilibrium of an artificial economy walras provides basic constructs for\\ndefining computational market structures and protocols for deriving their\\ncorresponding price equilibria in a particular realization of this approach\\nfor a form of multicommodity flow problem we see that careful construction of\\nthe decision process according to economic principles can lead to efficient\\ndistributed resource allocation and that the behavior of the system can be\\nmeaningfully analyzed in economic terms\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title_tokens\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summary_tokens\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title_tokens_no_stopwords\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summary_tokens_no_stopwords\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title_stemmed\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summary_stemmed\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"preprocessed_text\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"preprocessed_text_str\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"marketori program environ applic distribut multicommod flow problem market price system constitut wellunderstood class mechan certain condit provid effect decentr decis make minim commun overhead marketori program approach distribut problem solv deriv activ resourc alloc set comput agent comput competit equilibrium artifici economi walra provid basic construct defin comput market structur protocol deriv correspond price equilibria particular realiz approach form multicommod flow problem see care construct decis process accord econom principl lead effici distribut resourc alloc behavior system meaning analyz econom term\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#extract research paper\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "import kagglehub\n",
        "import os # Import the os module\n",
        "\n",
        "# Download necessary NLTK data\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('punkt_tab', quiet=True)\n",
        "\n",
        "\n",
        "# Download the dataset and get the path to the downloaded files\n",
        "data_path = kagglehub.dataset_download(\"sumitm004/arxiv-scientific-research-papers-dataset\")\n",
        "\n",
        "# Assuming the downloaded dataset contains a CSV file, find the CSV file\n",
        "# You might need to adjust the glob pattern based on the actual file name(s) in the dataset\n",
        "csv_files = [f for f in os.listdir(data_path) if f.endswith('.csv')]\n",
        "\n",
        "if not csv_files:\n",
        "    raise FileNotFoundError(\"No CSV file found in the downloaded dataset.\")\n",
        "\n",
        "# Assuming there is only one CSV file, or the first one is the main data file\n",
        "csv_file_path = os.path.join(data_path, csv_files[0])\n",
        "\n",
        "# Load the data from the CSV file into a pandas DataFrame\n",
        "df = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Display the column names to check for 'abstract'\n",
        "print(df.columns)\n",
        "\n",
        "# 2. Clean the 'title' and 'abstract' columns\n",
        "def clean_text(text):\n",
        "    if isinstance(text, str): # Add a check for string type\n",
        "        text = text.lower()\n",
        "        text = re.sub(r'[^\\w\\s]', '', text)\n",
        "        return text\n",
        "    return \"\" # Return empty string for non-string types\n",
        "\n",
        "df['title_cleaned'] = df['title'].apply(clean_text)\n",
        "df['summary_cleaned'] = df['summary'].apply(clean_text)\n",
        "\n",
        "# 3. Tokenize the cleaned text\n",
        "df['title_tokens'] = df['title_cleaned'].apply(word_tokenize)\n",
        "df['summary_tokens'] = df['summary_cleaned'].apply(word_tokenize)\n",
        "\n",
        "# 4. Remove stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def remove_stopwords(tokens):\n",
        "    return [word for word in tokens if word not in stop_words]\n",
        "\n",
        "df['title_tokens_no_stopwords'] = df['title_tokens'].apply(remove_stopwords)\n",
        "df['summary_tokens_no_stopwords'] = df['summary_tokens'].apply(remove_stopwords)\n",
        "\n",
        "# 5. Apply stemming\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "def stem_tokens(tokens):\n",
        "    return [stemmer.stem(word) for word in tokens]\n",
        "\n",
        "df['title_stemmed'] = df['title_tokens_no_stopwords'].apply(stem_tokens)\n",
        "df['summary_stemmed'] = df['summary_tokens_no_stopwords'].apply(stem_tokens)\n",
        "\n",
        "# 6. Combine the preprocessed tokens\n",
        "df['preprocessed_text'] = df.apply(lambda row: row['title_stemmed'] + row['summary_stemmed'], axis=1)\n",
        "\n",
        "# 7. Join the list of combined tokens into a single string\n",
        "df['preprocessed_text_str'] = df['preprocessed_text'].apply(lambda tokens: ' '.join(tokens))\n",
        "\n",
        "display(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "37e6f674",
        "outputId": "6770e814-b8df-4cde-b7e8-18790b2da3b4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
              "\twith 10026577 stored elements and shape (136238, 216485)>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Instantiate TfidfVectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Fit and transform the 'preprocessed_text_str' column\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(df['preprocessed_text_str'])\n",
        "\n",
        "display(tfidf_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "df60c16c"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def recommend_papers(user_query, tfidf_vectorizer, tfidf_matrix, df):\n",
        "    \"\"\"\n",
        "    Recommends papers based on cosine similarity with a user query.\n",
        "\n",
        "    Args:\n",
        "        user_query (str): The user's topic string.\n",
        "        tfidf_vectorizer: The fitted TfidfVectorizer.\n",
        "        tfidf_matrix: The TF-IDF matrix of the papers.\n",
        "        df (pd.DataFrame): The DataFrame containing the paper information.\n",
        "\n",
        "    Returns:\n",
        "        pd.Series: A series of similarity scores between the query and each paper.\n",
        "    \"\"\"\n",
        "    # Preprocess the user query\n",
        "    cleaned_query = clean_text(user_query)\n",
        "    tokens_query = word_tokenize(cleaned_query)\n",
        "    tokens_no_stopwords_query = remove_stopwords(tokens_query)\n",
        "    stemmed_query = stem_tokens(tokens_no_stopwords_query)\n",
        "    preprocessed_query_str = ' '.join(stemmed_query)\n",
        "\n",
        "    # Transform the preprocessed query into a TF-IDF vector\n",
        "    query_tfidf = tfidf_vectorizer.transform([preprocessed_query_str])\n",
        "\n",
        "    # Calculate cosine similarity\n",
        "    similarity_scores = cosine_similarity(query_tfidf, tfidf_matrix)\n",
        "\n",
        "    # Return the similarity scores as a pandas Series\n",
        "    return pd.Series(similarity_scores[0])\n",
        "\n",
        "# Example usage (optional, can be removed later)\n",
        "# user_topic = \"artificial intelligence in healthcare\"\n",
        "# similarity_scores = recommend_papers(user_topic, tfidf_vectorizer, tfidf_matrix, df)\n",
        "# print(similarity_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "709f17e9",
        "outputId": "dee50b87-f357-401b-ef99-ccc88982389c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                    id                                              title  \\\n",
              "7147  abs-2304.02924v1  The Governance of Physical Artificial Intellig...   \n",
              "5986  abs-2107.13454v1  Artificial Intelligence in Healthcare: Lost In...   \n",
              "\n",
              "                     category category_code published_date updated_date  \\\n",
              "7147  Artificial Intelligence         cs.AI         4/6/23       4/6/23   \n",
              "5986  Artificial Intelligence         cs.AI        7/28/21      7/28/21   \n",
              "\n",
              "                                                authors      first_author  \\\n",
              "7147  ['Yingbo Li', 'Anamaria-Beatrice Spulber', 'Yu...       'Yingbo Li'   \n",
              "5986             ['Vince I. Madai', 'David C. Higgins']  'Vince I. Madai'   \n",
              "\n",
              "                                                summary  summary_word_count  \\\n",
              "7147  Physical artificial intelligence can prove to ...                  32   \n",
              "5986  Artificial intelligence (AI) in healthcare is ...                 123   \n",
              "\n",
              "                                          title_cleaned  \\\n",
              "7147  the governance of physical artificial intellig...   \n",
              "5986  artificial intelligence in healthcare lost in ...   \n",
              "\n",
              "                                        summary_cleaned  \\\n",
              "7147  physical artificial intelligence can prove to ...   \n",
              "5986  artificial intelligence ai in healthcare is a ...   \n",
              "\n",
              "                                           title_tokens  \\\n",
              "7147  [the, governance, of, physical, artificial, in...   \n",
              "5986  [artificial, intelligence, in, healthcare, los...   \n",
              "\n",
              "                                         summary_tokens  \\\n",
              "7147  [physical, artificial, intelligence, can, prov...   \n",
              "5986  [artificial, intelligence, ai, in, healthcare,...   \n",
              "\n",
              "                              title_tokens_no_stopwords  \\\n",
              "7147   [governance, physical, artificial, intelligence]   \n",
              "5986  [artificial, intelligence, healthcare, lost, t...   \n",
              "\n",
              "                            summary_tokens_no_stopwords  \\\n",
              "7147  [physical, artificial, intelligence, prove, on...   \n",
              "5986  [artificial, intelligence, ai, healthcare, pot...   \n",
              "\n",
              "                                        title_stemmed  \\\n",
              "7147             [govern, physic, artifici, intellig]   \n",
              "5986  [artifici, intellig, healthcar, lost, translat]   \n",
              "\n",
              "                                        summary_stemmed  \\\n",
              "7147  [physic, artifici, intellig, prove, one, impor...   \n",
              "5986  [artifici, intellig, ai, healthcar, potenti, r...   \n",
              "\n",
              "                                      preprocessed_text  \\\n",
              "7147  [govern, physic, artifici, intellig, physic, a...   \n",
              "5986  [artifici, intellig, healthcar, lost, translat...   \n",
              "\n",
              "                                  preprocessed_text_str  \n",
              "7147  govern physic artifici intellig physic artific...  \n",
              "5986  artifici intellig healthcar lost translat arti...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c83faf4b-ee42-489e-8dae-447e397c8b56\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>category</th>\n",
              "      <th>category_code</th>\n",
              "      <th>published_date</th>\n",
              "      <th>updated_date</th>\n",
              "      <th>authors</th>\n",
              "      <th>first_author</th>\n",
              "      <th>summary</th>\n",
              "      <th>summary_word_count</th>\n",
              "      <th>title_cleaned</th>\n",
              "      <th>summary_cleaned</th>\n",
              "      <th>title_tokens</th>\n",
              "      <th>summary_tokens</th>\n",
              "      <th>title_tokens_no_stopwords</th>\n",
              "      <th>summary_tokens_no_stopwords</th>\n",
              "      <th>title_stemmed</th>\n",
              "      <th>summary_stemmed</th>\n",
              "      <th>preprocessed_text</th>\n",
              "      <th>preprocessed_text_str</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7147</th>\n",
              "      <td>abs-2304.02924v1</td>\n",
              "      <td>The Governance of Physical Artificial Intellig...</td>\n",
              "      <td>Artificial Intelligence</td>\n",
              "      <td>cs.AI</td>\n",
              "      <td>4/6/23</td>\n",
              "      <td>4/6/23</td>\n",
              "      <td>['Yingbo Li', 'Anamaria-Beatrice Spulber', 'Yu...</td>\n",
              "      <td>'Yingbo Li'</td>\n",
              "      <td>Physical artificial intelligence can prove to ...</td>\n",
              "      <td>32</td>\n",
              "      <td>the governance of physical artificial intellig...</td>\n",
              "      <td>physical artificial intelligence can prove to ...</td>\n",
              "      <td>[the, governance, of, physical, artificial, in...</td>\n",
              "      <td>[physical, artificial, intelligence, can, prov...</td>\n",
              "      <td>[governance, physical, artificial, intelligence]</td>\n",
              "      <td>[physical, artificial, intelligence, prove, on...</td>\n",
              "      <td>[govern, physic, artifici, intellig]</td>\n",
              "      <td>[physic, artifici, intellig, prove, one, impor...</td>\n",
              "      <td>[govern, physic, artifici, intellig, physic, a...</td>\n",
              "      <td>govern physic artifici intellig physic artific...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5986</th>\n",
              "      <td>abs-2107.13454v1</td>\n",
              "      <td>Artificial Intelligence in Healthcare: Lost In...</td>\n",
              "      <td>Artificial Intelligence</td>\n",
              "      <td>cs.AI</td>\n",
              "      <td>7/28/21</td>\n",
              "      <td>7/28/21</td>\n",
              "      <td>['Vince I. Madai', 'David C. Higgins']</td>\n",
              "      <td>'Vince I. Madai'</td>\n",
              "      <td>Artificial intelligence (AI) in healthcare is ...</td>\n",
              "      <td>123</td>\n",
              "      <td>artificial intelligence in healthcare lost in ...</td>\n",
              "      <td>artificial intelligence ai in healthcare is a ...</td>\n",
              "      <td>[artificial, intelligence, in, healthcare, los...</td>\n",
              "      <td>[artificial, intelligence, ai, in, healthcare,...</td>\n",
              "      <td>[artificial, intelligence, healthcare, lost, t...</td>\n",
              "      <td>[artificial, intelligence, ai, healthcare, pot...</td>\n",
              "      <td>[artifici, intellig, healthcar, lost, translat]</td>\n",
              "      <td>[artifici, intellig, ai, healthcar, potenti, r...</td>\n",
              "      <td>[artifici, intellig, healthcar, lost, translat...</td>\n",
              "      <td>artifici intellig healthcar lost translat arti...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c83faf4b-ee42-489e-8dae-447e397c8b56')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c83faf4b-ee42-489e-8dae-447e397c8b56 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c83faf4b-ee42-489e-8dae-447e397c8b56');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-58e5dd57-2f38-4639-a612-04b7708b758d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-58e5dd57-2f38-4639-a612-04b7708b758d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-58e5dd57-2f38-4639-a612-04b7708b758d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_32992303-2932-48eb-84e8-82edf2ef0378\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('recommended_papers')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_32992303-2932-48eb-84e8-82edf2ef0378 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('recommended_papers');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "recommended_papers",
              "repr_error": "0"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "def recommend_papers(user_query, tfidf_vectorizer, tfidf_matrix, df, N=5):\n",
        "    \"\"\"\n",
        "    Recommends top N papers based on cosine similarity with a user query.\n",
        "\n",
        "    Args:\n",
        "        user_query (str): The user's topic string.\n",
        "        tfidf_vectorizer: The fitted TfidfVectorizer.\n",
        "        tfidf_matrix: The TF-IDF matrix of the papers.\n",
        "        df (pd.DataFrame): The DataFrame containing the paper information.\n",
        "        N (int): The number of top recommendations to return.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame containing the top N recommended papers' information.\n",
        "    \"\"\"\n",
        "    # Preprocess the user query\n",
        "    cleaned_query = clean_text(user_query)\n",
        "    tokens_query = word_tokenize(cleaned_query)\n",
        "    tokens_no_stopwords_query = remove_stopwords(tokens_query)\n",
        "    stemmed_query = stem_tokens(tokens_no_stopwords_query)\n",
        "    preprocessed_query_str = ' '.join(stemmed_query)\n",
        "\n",
        "    # Transform the preprocessed query into a TF-IDF vector\n",
        "    query_tfidf = tfidf_vectorizer.transform([preprocessed_query_str])\n",
        "\n",
        "    # Calculate cosine similarity\n",
        "    similarity_scores = cosine_similarity(query_tfidf, tfidf_matrix)\n",
        "\n",
        "    # Get the indices of the top N most similar papers\n",
        "    # Use argsort and slicing\n",
        "    top_n_indices = similarity_scores[0].argsort()[-N:][::-1]\n",
        "\n",
        "    # Retrieve the information of the top N papers\n",
        "    recommended_papers_info = df.iloc[top_n_indices]\n",
        "\n",
        "    return recommended_papers_info\n",
        "\n",
        "# Example usage:\n",
        "user_topic = \"artificial intelligence in healthcare\"\n",
        "recommended_papers = recommend_papers(user_topic, tfidf_vectorizer, tfidf_matrix, df, N=2)\n",
        "display(recommended_papers)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C4VGtb4PUkj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F1BWC-G9Uk0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pyxJxT6bUlFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hkrFZyGqUlUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c-kKxe-jd9aB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PzkAbFb4d9oT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ybt_HwOFd9rM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9ibjAy_0d9u6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sentiment analysis\n",
        "\n",
        "\n",
        "# ==============================\n",
        "# 1. Install Dependencies\n",
        "# ==============================\n",
        "!pip install datasets transformers torch torchvision torchaudio\n",
        "!pip install xgboost scikit-learn keras\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8vbPO5nVCey",
        "outputId": "841aad4c-6ba9-4534-edaa-c782215d0880"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.19.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.35.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2025.8.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.12/dist-packages (3.0.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.0.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.27.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from xgboost) (1.16.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras) (0.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (from keras) (3.14.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras) (0.17.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.12/dist-packages (from keras) (0.5.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from keras) (25.0)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from optree->keras) (4.15.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.16.1\n",
        "!pip install torch torchvision torchaudio\n",
        "!pip install transformers==4.44.2 datasets\n",
        "!pip install xgboost==2.1.1 scikit-learn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XpNR_1FeYuvY",
        "outputId": "ab17c055-e173-43b6-aa52-e7ab995411df"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==2.16.1\n",
            "  Downloading tensorflow-2.16.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.16.1) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.16.1) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.16.1) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.16.1) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.16.1) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.16.1) (3.14.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.16.1) (18.1.1)\n",
            "Collecting ml-dtypes~=0.3.1 (from tensorflow==2.16.1)\n",
            "  Downloading ml_dtypes-0.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.16.1) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.16.1) (25.0)\n",
            "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow==2.16.1)\n",
            "  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.16.1) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.16.1) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.16.1) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.16.1) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.16.1) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.16.1) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.16.1) (1.75.0)\n",
            "Collecting tensorboard<2.17,>=2.16 (from tensorflow==2.16.1)\n",
            "  Downloading tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: keras>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.16.1) (3.10.0)\n",
            "Collecting numpy<2.0.0,>=1.26.0 (from tensorflow==2.16.1)\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow==2.16.1) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.0.0->tensorflow==2.16.1) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.0.0->tensorflow==2.16.1) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.0.0->tensorflow==2.16.1) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow==2.16.1) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow==2.16.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow==2.16.1) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow==2.16.1) (2025.8.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.1) (3.9)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.1) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.1) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow==2.16.1) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.0.0->tensorflow==2.16.1) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.0.0->tensorflow==2.16.1) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow==2.16.1) (0.1.2)\n",
            "Downloading tensorflow-2.16.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (589.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m589.9/589.9 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m86.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m101.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: protobuf, numpy, tensorboard, ml-dtypes, tensorflow\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.5\n",
            "    Uninstalling protobuf-5.29.5:\n",
            "      Successfully uninstalled protobuf-5.29.5\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.19.0\n",
            "    Uninstalling tensorboard-2.19.0:\n",
            "      Successfully uninstalled tensorboard-2.19.0\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml_dtypes 0.5.3\n",
            "    Uninstalling ml_dtypes-0.5.3:\n",
            "      Successfully uninstalled ml_dtypes-0.5.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.19.0\n",
            "    Uninstalling tensorflow-2.19.0:\n",
            "      Successfully uninstalled tensorflow-2.19.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "tensorflow-decision-forests 1.12.0 requires tensorflow==2.19.0, but you have tensorflow 2.16.1 which is incompatible.\n",
            "tensorflow-text 2.19.0 requires tensorflow<2.20,>=2.19.0, but you have tensorflow 2.16.1 which is incompatible.\n",
            "jax 0.5.3 requires ml_dtypes>=0.4.0, but you have ml-dtypes 0.3.2 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "tf-keras 2.19.0 requires tensorflow<2.20,>=2.19, but you have tensorflow 2.16.1 which is incompatible.\n",
            "tensorstore 0.1.76 requires ml_dtypes>=0.5.0, but you have ml-dtypes 0.3.2 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed ml-dtypes-0.3.2 numpy-1.26.4 protobuf-4.25.8 tensorboard-2.16.2 tensorflow-2.16.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "numpy"
                ]
              },
              "id": "3558fccbc56445f0b6b3f522a10f6dcf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2899960281.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install tensorflow==2.16.1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install torch torchvision torchaudio'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install transformers==4.44.2 datasets'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install xgboost==2.1.1 scikit-learn'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m       \u001b[0m_pip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_previous_import_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_send_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_pip.py\u001b[0m in \u001b[0;36mprint_previous_import_warning\u001b[0;34m(output)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprint_previous_import_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m   \u001b[0;34m\"\"\"Prints a warning about previously imported packages.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m   \u001b[0mpackages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_previously_imported_packages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mpackages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# display a list of packages using the colab-display-data mimetype, which\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_pip.py\u001b[0m in \u001b[0;36m_previously_imported_packages\u001b[0;34m(pip_output)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_previously_imported_packages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpip_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m   \u001b[0;34m\"\"\"List all previously imported packages from a pip install.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m   \u001b[0minstalled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_extract_toplevel_packages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpip_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstalled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_pip.py\u001b[0m in \u001b[0;36m_extract_toplevel_packages\u001b[0;34m(pip_output)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;34m\"\"\"Extract the list of toplevel packages associated with a pip install.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0mtoplevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mps\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpackages_distributions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m       \u001b[0mtoplevel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mpackages_distributions\u001b[0;34m()\u001b[0m\n\u001b[1;32m    945\u001b[0m     \u001b[0mpkg_to_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdistributions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mpkg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_top_level_declared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_top_level_inferred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m             \u001b[0mpkg_to_dist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpkg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpkg_to_dist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36m_top_level_inferred\u001b[0;34m(dist)\u001b[0m\n\u001b[1;32m    957\u001b[0m     opt_names = {\n\u001b[1;32m    958\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetmodulename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 959\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0malways_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    960\u001b[0m     }\n\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mfiles\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    498\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m         return skip_missing_files(\n\u001b[0m\u001b[1;32m    501\u001b[0m             make_files(\n\u001b[1;32m    502\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_files_distinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/_functools.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(param, *args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mskip_missing_files\u001b[0;34m(package_paths)\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mpass_none\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mskip_missing_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         return skip_missing_files(\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mpass_none\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mskip_missing_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         return skip_missing_files(\n",
            "\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36mexists\u001b[0;34m(self, follow_symlinks)\u001b[0m\n\u001b[1;32m    858\u001b[0m         \"\"\"\n\u001b[1;32m    859\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_ignore_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36mstat\u001b[0;34m(self, follow_symlinks)\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mdoes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m         \"\"\"\n\u001b[0;32m--> 840\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "\n",
        "# ✅ Use tf.keras instead of keras standalone\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense"
      ],
      "metadata": {
        "id": "x9gp2KnzJrZX"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "\n",
        "dataset = load_dataset(\"imdb\")\n",
        "\n",
        "# Convert to DataFrame for easier handling\n",
        "train_df = pd.DataFrame(dataset[\"train\"])\n",
        "test_df = pd.DataFrame(dataset[\"test\"])\n",
        "\n",
        "# Sample a balanced subset\n",
        "train_df = train_df.sample(n=10000, random_state=42)  # 10k random\n",
        "test_df = test_df.sample(n=2000, random_state=42)     # 2k random\n",
        "\n",
        "train_texts = train_df[\"text\"].tolist()\n",
        "train_labels = train_df[\"label\"].tolist()\n",
        "test_texts = test_df[\"text\"].tolist()\n",
        "test_labels = test_df[\"label\"].tolist()\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    train_texts, train_labels,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=train_labels   # ✅ keep class balance\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374,
          "referenced_widgets": [
            "eee3f96f90614806ba04f8023de71a74",
            "49a3ca060e2e4b04b4e41c8789d116fd",
            "b158454ecd5c4bd496eaa8bcbc468df7",
            "c8405ac926154763ba0d869146a98de4",
            "d86f6de623b945ea9b75f66850c38c64",
            "677d747ea1c54cffb097854ce67f8a2e",
            "ad5a84a147784685a53ec320216d102b",
            "bed0fe0787284e559a6064c14bdf7616",
            "7801ef4f7230452bbee3851df501c82d",
            "cbf65b552cdf4ae7a5b589b44586d4cd",
            "c39001f0a6b347049f8e25cff6fde71d",
            "c01f17ce01dd40dd90d3396affa1d513",
            "e17a314713594c14bc9487480b904c02",
            "e095a4b592d8424f9c047b9fbc41705f",
            "facdf5fecc484c06970be5755ec96db2",
            "1ffdc8d1a9434f29857621a96425e87a",
            "aa281fe7ffe341e09bda4bf22dd9af50",
            "7ad5982588294a3098f35ba678c23a09",
            "041a50df4b6d4ed18fc0efa807e82ff1",
            "bbbd66e16d1748208442ad2675ab01fc",
            "13213d6909f34d92b9d44c8abf70375d",
            "0caa303ad06942ce96ba87c676b150da",
            "4e0cdfbe214047418b0ff6234f559dcc",
            "397853e8d090459a9c2fe3e77fcf8d1b",
            "9f2e02a4e28641c6977da46aa9b711ce",
            "e4e16b6b7a9b453289db3103b8cfe022",
            "15c329fec70346a5bd5e4f93f70cfdc1",
            "37c1e8d411294955920a3ef67503f508",
            "d8a710ce9262490f806ecaeeb3acfff2",
            "abeddd281a774684a56f76a9be05e432",
            "80a01e2ed89545379e43e93280b41780",
            "18ebe72e101346e980b3e823592c8a9f",
            "7d0f2be5158842cd838b5600cbd787b6",
            "beb3c73e0f314d7bae0260bea0857a7d",
            "7fb1825dcfe94e09b98877852c94f8ca",
            "b8b106cd1b67466889fe60950f14c50d",
            "b1b9a36c88e74ae7adb36903f5c29e7a",
            "c8391e7dce5c4e528e8ee9a5421b6717",
            "9218dc59f1984db5b3a51b431dbd1929",
            "1d07511b7e1e45dda555b3539d6071ff",
            "c1127c23fe9f42ee9d11713080449116",
            "94404791b5e94d71850dd96dffa88608",
            "e93366a5bc9643ed8e431c89e145522c",
            "f8b5b9df6ba94cf5a5e7a6c3b5e09bd2",
            "e9d2f7077b8c44cb92ff06ad1a621579",
            "0285425bb6154d29ad0df2963348f677",
            "d8044a3d171a472194be04cff1bc6452",
            "15ef8cab1e5a488787280b41b92f5eff",
            "5627514a8be24fc78c0b069335080bc0",
            "b11dd745b9a242ab9718fd6f8f231ae4",
            "58437fc54d2446dd98478e6812001abf",
            "d54beff1584f4e66be4be4dd4f244630",
            "fdd67dc421804821b9eae71422af401b",
            "2337cc0c0f064715be8335ba33481577",
            "6644cb20030b479e9e1a3d6db8befae5",
            "61d52cba2e6947b2940a63865c3ea14e",
            "ddc8354db73a4a17b004a59354b6bd93",
            "33f021df80574c319b5f1a97a4835a04",
            "9d5e5b3d23b548449dcbefab70efc0ea",
            "e4005302e5b6485499a3af17d68927bd",
            "ae833fc5adf840feb06276f8d98afe26",
            "6b529adcf5374d3e840ace4a750d80d1",
            "649badb850f547b6ba86ddd7d3874496",
            "6e80bd8525014fd8ba10a24e5554c0aa",
            "c316c715fcfa49559d89dc52696c4873",
            "050326db98ed4b1ea039cb5cb5cc4033",
            "3810e7f0fb1c4ac3b9efcadfcdbb6d80",
            "ed2deb0413f04838ade5c9927c92dcd9",
            "d6be8db52332424580d0cc3d93a39e25",
            "d2c53bbc209c414fb0d8bd1e269ab6c5",
            "0b02007d61fd4d0cb587ebc17ce78e73",
            "0f8d943693494bdf9c88474987bb8545",
            "eb37a9d6b80143548050a50132a3261f",
            "55eaeba2f64e4faa989da46d88be83d6",
            "120d00197d8d40218541705333cdb965",
            "208e616f888c408dbc6772eb639b61b8",
            "daf2b26f75da42b1b63fafcff96c6cf7"
          ]
        },
        "id": "G0FwN3jmXi2d",
        "outputId": "9e319be7-3077-404a-8818-d1bbab8c0550"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eee3f96f90614806ba04f8023de71a74"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "plain_text/train-00000-of-00001.parquet:   0%|          | 0.00/21.0M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c01f17ce01dd40dd90d3396affa1d513"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "plain_text/test-00000-of-00001.parquet:   0%|          | 0.00/20.5M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4e0cdfbe214047418b0ff6234f559dcc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "plain_text/unsupervised-00000-of-00001.p(…):   0%|          | 0.00/42.0M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "beb3c73e0f314d7bae0260bea0857a7d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e9d2f7077b8c44cb92ff06ad1a621579"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "61d52cba2e6947b2940a63865c3ea14e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3810e7f0fb1c4ac3b9efcadfcdbb6d80"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# 3. Logistic Regression (TF-IDF)\n",
        "# ==============================\n",
        "tfidf = TfidfVectorizer(max_features=10000)\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_val_tfidf = tfidf.transform(X_val)\n",
        "\n",
        "log_reg = LogisticRegression(max_iter=200)\n",
        "log_reg.fit(X_train_tfidf, y_train)\n",
        "\n",
        "lr_val_preds = log_reg.predict_proba(X_val_tfidf)[:, 1]"
      ],
      "metadata": {
        "id": "UhOKU0gPaLTr"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# 4. LSTM Model\n",
        "# ==============================\n",
        "tokenizer_lstm = Tokenizer(num_words=10000)\n",
        "tokenizer_lstm.fit_on_texts(X_train)\n",
        "\n",
        "X_train_seq = tokenizer_lstm.texts_to_sequences(X_train)\n",
        "X_val_seq = tokenizer_lstm.texts_to_sequences(X_val)\n",
        "\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=200)\n",
        "X_val_pad = pad_sequences(X_val_seq, maxlen=200)\n",
        "\n",
        "lstm_model = Sequential([\n",
        "    Embedding(input_dim=10000, output_dim=64, input_length=200),\n",
        "    LSTM(64),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "lstm_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "lstm_model.fit(\n",
        "    X_train_pad, np.array(y_train),\n",
        "    epochs=2, batch_size=32, verbose=1, validation_split=0.1\n",
        ")\n",
        "\n",
        "lstm_val_preds = lstm_model.predict(X_val_pad).flatten()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dP0mSjpaaPTB",
        "outputId": "5665e01b-bb05-4ede-e20d-ef42932552ae"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.5977 - loss: 0.6576 - val_accuracy: 0.8012 - val_loss: 0.4265\n",
            "Epoch 2/2\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8701 - loss: 0.3140 - val_accuracy: 0.8338 - val_loss: 0.3870\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# 5. BERT Fine-tuning\n",
        "# ==============================\n",
        "tokenizer_bert = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "train_encodings = tokenizer_bert(\n",
        "    list(X_train), truncation=True, padding=True, max_length=128, return_tensors=\"pt\"\n",
        ")\n",
        "val_encodings = tokenizer_bert(\n",
        "    list(X_val), truncation=True, padding=True, max_length=128, return_tensors=\"pt\"\n",
        ")\n",
        "\n",
        "class IMDbDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "train_dataset = IMDbDataset(train_encodings, y_train)\n",
        "val_dataset = IMDbDataset(val_encodings, y_val)\n",
        "\n",
        "bert_model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", num_labels=2\n",
        ")\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    num_train_epochs=1,   # increase for better performance\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=50,\n",
        "    eval_strategy=\"epoch\", # Corrected parameter name\n",
        "    save_strategy=\"no\"\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=bert_model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "# Get BERT predictions\n",
        "bert_val_preds = trainer.predict(val_dataset).predictions\n",
        "bert_val_probs = torch.softmax(torch.tensor(bert_val_preds), dim=1)[:, 1].numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "id": "RdbMmOc9bOMp",
        "outputId": "c87a2046-15cf-41c6-eb48-a978cc8da3fc"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msunilreddyj123\u001b[0m (\u001b[33msunilreddyj123-alliance-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.21.4"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251003_093143-yzmn7bro</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/sunilreddyj123-alliance-university/huggingface/runs/yzmn7bro' target=\"_blank\">silvery-vortex-2</a></strong> to <a href='https://wandb.ai/sunilreddyj123-alliance-university/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/sunilreddyj123-alliance-university/huggingface' target=\"_blank\">https://wandb.ai/sunilreddyj123-alliance-university/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/sunilreddyj123-alliance-university/huggingface/runs/yzmn7bro' target=\"_blank\">https://wandb.ai/sunilreddyj123-alliance-university/huggingface/runs/yzmn7bro</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Detected [huggingface_hub.inference, mcp] in use.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: For more information, check out the docs at: https://weave-docs.wandb.ai/\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1000/1000 03:31, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.276400</td>\n",
              "      <td>0.351857</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# 6. Stacking Ensemble (XGBoost)\n",
        "# ==============================\n",
        "stacked_features = np.vstack([lr_val_preds, lstm_val_preds, bert_val_probs]).T\n",
        "\n",
        "meta_model = XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\")\n",
        "meta_model.fit(stacked_features, y_val)\n",
        "\n",
        "final_preds = meta_model.predict(stacked_features)\n",
        "\n",
        "print(\"\\nClassification Report (Stacked Ensemble):\")\n",
        "print(classification_report(y_val, final_preds))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRH4uofAbgqk",
        "outputId": "dd39d493-fb88-4224-ab63-5566462543a3"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report (Stacked Ensemble):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00      1008\n",
            "           1       0.99      1.00      1.00       992\n",
            "\n",
            "    accuracy                           1.00      2000\n",
            "   macro avg       1.00      1.00      1.00      2000\n",
            "weighted avg       1.00      1.00      1.00      2000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [09:35:49] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# 7. Inference Function\n",
        "# ==============================\n",
        "def predict_sentiment(text):\n",
        "    # --- Logistic Regression ---\n",
        "    tfidf_features = tfidf.transform([text])\n",
        "    lr_pred = log_reg.predict_proba(tfidf_features)[:, 1]\n",
        "\n",
        "    # --- LSTM ---\n",
        "    seq = tokenizer_lstm.texts_to_sequences([text])\n",
        "    pad_seq = pad_sequences(seq, maxlen=200)\n",
        "    lstm_pred = lstm_model.predict(pad_seq).flatten()\n",
        "\n",
        "    # --- BERT ---\n",
        "    enc = tokenizer_bert(text, truncation=True, padding=True, max_length=128, return_tensors=\"pt\")\n",
        "    # Move tensors to the same device as the model\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    enc = {k: v.to(device) for k, v in enc.items()}\n",
        "    bert_model.to(device) # Ensure model is on the same device\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = bert_model(**enc)\n",
        "        probs = torch.softmax(outputs.logits, dim=1)\n",
        "    bert_pred = probs[:, 1].cpu().numpy() # Move back to CPU for numpy conversion\n",
        "\n",
        "    # --- Combine Predictions ---\n",
        "    stacked = np.vstack([lr_pred, lstm_pred, bert_pred]).T\n",
        "    final_pred = meta_model.predict(stacked)[0]\n",
        "\n",
        "    sentiment = \"Positive 😀\" if final_pred == 1 else \"Negative 😡\"\n",
        "    return sentiment\n",
        "\n",
        "# ==============================\n",
        "# 8. Test Custom Inputs\n",
        "# ==============================\n",
        "print(predict_sentiment(\"The movie was absolutely wonderful, I loved it!\"))\n",
        "print(predict_sentiment(\"Worst film ever, complete waste of time\"))\n",
        "print(predict_sentiment(\"It was okay, not great but not terrible\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_3cH0HUdM6h",
        "outputId": "b336159c-c53c-4584-d6ae-54c0dfdacbe5"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
            "Positive 😀\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Negative 😡\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Negative 😡\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-YbUK4eveAss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#news division"
      ],
      "metadata": {
        "id": "pg_fAIMreAvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "newsgroups = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))\n",
        "X, y = newsgroups.data, newsgroups.target\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# TF-IDF Vectorization\n",
        "vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7)\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "# Define models\n",
        "models = {\n",
        "    \"MultinomialNB\": MultinomialNB(),\n",
        "    \"LogisticRegression\": LogisticRegression(max_iter=200),\n",
        "    \"RandomForest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    \"SVM\": SVC(kernel='linear', probability=True)\n",
        "}\n",
        "\n",
        "# Map 20 newsgroups into Big-8 Hierarchies\n",
        "big8_mapping = {\n",
        "    # Computers\n",
        "    'comp.graphics': 'Computers', 'comp.os.ms-windows.misc': 'Computers',\n",
        "    'comp.sys.ibm.pc.hardware': 'Computers', 'comp.sys.mac.hardware': 'Computers',\n",
        "    'comp.windows.x': 'Computers',\n",
        "\n",
        "    # Humanities\n",
        "    'rec.autos': 'Miscellaneous', 'rec.motorcycles': 'Miscellaneous',\n",
        "\n",
        "    # Miscellaneous\n",
        "    'misc.forsale': 'Miscellaneous',\n",
        "\n",
        "    # News\n",
        "    'talk.politics.guns': 'Talk', 'talk.politics.mideast': 'Talk',\n",
        "    'talk.politics.misc': 'Talk', 'talk.religion.misc': 'Talk',\n",
        "\n",
        "    # Sports & Entertainment\n",
        "    'rec.sport.baseball': 'Sports and Entertainment', 'rec.sport.hockey': 'Sports and Entertainment',\n",
        "\n",
        "    # Scientific\n",
        "    'sci.crypt': 'Scientific', 'sci.electronics': 'Scientific', 'sci.med': 'Scientific', 'sci.space': 'Scientific',\n",
        "\n",
        "    # Social\n",
        "    'soc.religion.christian': 'Social',\n",
        "\n",
        "    # Other / fallback\n",
        "    'alt.atheism': 'Talk', 'news.misc': 'News', 'news.religion.christian': 'Social'\n",
        "}\n",
        "\n",
        "# Helper function to map newsgroup names to Big-8\n",
        "def map_to_big8(newsgroup_name):\n",
        "    return big8_mapping.get(newsgroup_name, 'Miscellaneous')\n",
        "\n",
        "# Train and evaluate models\n",
        "for name, model in models.items():\n",
        "    print(f\"\\n--- {name} ---\")\n",
        "    model.fit(X_train_tfidf, y_train)\n",
        "    y_pred = model.predict(X_test_tfidf)\n",
        "\n",
        "    # Convert predictions to Big-8\n",
        "    y_pred_big8 = [map_to_big8(newsgroups.target_names[i]) for i in y_pred]\n",
        "    y_test_big8 = [map_to_big8(newsgroups.target_names[i]) for i in y_test]\n",
        "\n",
        "    print(\"Accuracy:\", accuracy_score(y_test_big8, y_pred_big8))\n",
        "    print(\"Classification Report:\\n\", classification_report(y_test_big8, y_pred_big8))\n",
        "\n",
        "# Test with a custom news snippet\n",
        "sample_news = [\"NASA is planning to launch a new space telescope next year.\"]\n",
        "sample_tfidf = vectorizer.transform(sample_news)\n",
        "for name, model in models.items():\n",
        "    predicted_group = newsgroups.target_names[model.predict(sample_tfidf)[0]]\n",
        "    predicted_big8 = map_to_big8(predicted_group)\n",
        "    print(f\"{name} Prediction: {predicted_big8}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhvzQlvQeBFM",
        "outputId": "6de0154c-ddd4-4f71-912a-ccca9e5a037e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- MultinomialNB ---\n",
            "Accuracy: 0.813527851458886\n",
            "Classification Report:\n",
            "                           precision    recall  f1-score   support\n",
            "\n",
            "               Computers       0.90      0.90      0.90      1000\n",
            "           Miscellaneous       0.74      0.81      0.77       557\n",
            "              Scientific       0.84      0.83      0.84       786\n",
            "                  Social       0.43      0.94      0.59       202\n",
            "Sports and Entertainment       0.92      0.89      0.91       409\n",
            "                    Talk       0.93      0.62      0.75       816\n",
            "\n",
            "                accuracy                           0.81      3770\n",
            "               macro avg       0.79      0.83      0.79      3770\n",
            "            weighted avg       0.85      0.81      0.82      3770\n",
            "\n",
            "\n",
            "--- LogisticRegression ---\n",
            "Accuracy: 0.8368700265251989\n",
            "Classification Report:\n",
            "                           precision    recall  f1-score   support\n",
            "\n",
            "               Computers       0.92      0.88      0.90      1000\n",
            "           Miscellaneous       0.70      0.82      0.75       557\n",
            "              Scientific       0.82      0.84      0.83       786\n",
            "                  Social       0.69      0.81      0.74       202\n",
            "Sports and Entertainment       0.93      0.88      0.90       409\n",
            "                    Talk       0.88      0.78      0.83       816\n",
            "\n",
            "                accuracy                           0.84      3770\n",
            "               macro avg       0.82      0.83      0.83      3770\n",
            "            weighted avg       0.84      0.84      0.84      3770\n",
            "\n",
            "\n",
            "--- RandomForest ---\n",
            "Accuracy: 0.7954907161803714\n",
            "Classification Report:\n",
            "                           precision    recall  f1-score   support\n",
            "\n",
            "               Computers       0.86      0.88      0.87      1000\n",
            "           Miscellaneous       0.64      0.80      0.71       557\n",
            "              Scientific       0.81      0.76      0.78       786\n",
            "                  Social       0.63      0.78      0.70       202\n",
            "Sports and Entertainment       0.87      0.87      0.87       409\n",
            "                    Talk       0.87      0.69      0.77       816\n",
            "\n",
            "                accuracy                           0.80      3770\n",
            "               macro avg       0.78      0.80      0.78      3770\n",
            "            weighted avg       0.81      0.80      0.80      3770\n",
            "\n",
            "\n",
            "--- SVM ---\n",
            "Accuracy: 0.8368700265251989\n",
            "Classification Report:\n",
            "                           precision    recall  f1-score   support\n",
            "\n",
            "               Computers       0.91      0.87      0.89      1000\n",
            "           Miscellaneous       0.67      0.83      0.74       557\n",
            "              Scientific       0.81      0.84      0.83       786\n",
            "                  Social       0.75      0.79      0.77       202\n",
            "Sports and Entertainment       0.97      0.86      0.91       409\n",
            "                    Talk       0.88      0.80      0.84       816\n",
            "\n",
            "                accuracy                           0.84      3770\n",
            "               macro avg       0.83      0.83      0.83      3770\n",
            "            weighted avg       0.85      0.84      0.84      3770\n",
            "\n",
            "MultinomialNB Prediction: Scientific\n",
            "LogisticRegression Prediction: Scientific\n",
            "RandomForest Prediction: Scientific\n",
            "SVM Prediction: Scientific\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TmIhFYxDjUou"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#readability/ difficulty level\n",
        "!pip install textstat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkP2UVnF9CRH",
        "outputId": "6950a435-2601-472e-8eee-eb6b3ba47cbc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting textstat\n",
            "  Downloading textstat-0.7.10-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pyphen (from textstat)\n",
            "  Downloading pyphen-0.17.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from textstat) (3.9.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from textstat) (75.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->textstat) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->textstat) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk->textstat) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk->textstat) (4.67.1)\n",
            "Downloading textstat-0.7.10-py3-none-any.whl (239 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.2/239.2 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyphen-0.17.2-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyphen, textstat\n",
            "Successfully installed pyphen-0.17.2 textstat-0.7.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "from textstat import flesch_reading_ease\n",
        "\n",
        "class BalancedClassifier:\n",
        "    def __init__(self, vocab_file):\n",
        "        self.vocab_df = pd.read_csv(vocab_file)\n",
        "        self.vocab_levels = dict(zip(\n",
        "            self.vocab_df['headword'].str.lower(),\n",
        "            self.vocab_df['CEFR']\n",
        "        ))\n",
        "\n",
        "    def classify(self, text):\n",
        "        \"\"\"Simple but effective classification\"\"\"\n",
        "        if not text.strip() or len(text.split()) < 8:\n",
        "            return \"elementary\"\n",
        "\n",
        "        # Get basic features\n",
        "        words = re.findall(r'\\b[a-z]+\\b', text.lower())\n",
        "        sentences = [s.strip() for s in re.split(r'[.!?]+', text) if s.strip()]\n",
        "\n",
        "        if not words or not sentences:\n",
        "            return \"elementary\"\n",
        "\n",
        "        # Calculate key metrics\n",
        "        avg_sentence_length = len(words) / len(sentences)\n",
        "        readability = flesch_reading_ease(text)\n",
        "\n",
        "        # Vocabulary analysis - focus on B1/B2 words\n",
        "        intermediate_words = 0\n",
        "        advanced_words = 0\n",
        "        basic_words = 0\n",
        "\n",
        "        for word in words:\n",
        "            if word in self.vocab_levels:\n",
        "                level = self.vocab_levels[word]\n",
        "                if level in ['A1', 'A2']:\n",
        "                    basic_words += 1\n",
        "                elif level in ['B1', 'B2']:\n",
        "                    intermediate_words += 1\n",
        "                else:  # C1, C2\n",
        "                    advanced_words += 1\n",
        "\n",
        "        total_known_words = basic_words + intermediate_words + advanced_words\n",
        "        if total_known_words == 0:\n",
        "            return \"elementary\"\n",
        "\n",
        "        intermediate_ratio = intermediate_words / len(words)\n",
        "        advanced_ratio = advanced_words / len(words)\n",
        "        basic_ratio = basic_words / len(words)\n",
        "\n",
        "        # DECISION TREE - Much simpler logic\n",
        "        # Rule 1: If lots of advanced words → Advanced\n",
        "        if advanced_ratio > 0.15:  # More than 15% advanced words\n",
        "            return \"advanced\"\n",
        "\n",
        "        # Rule 2: If very simple vocabulary and structure → Elementary\n",
        "        if (basic_ratio > 0.8 and          # 80%+ basic words\n",
        "            avg_sentence_length < 12 and   # Short sentences\n",
        "            readability > 70):             # Very easy to read\n",
        "            return \"elementary\"\n",
        "\n",
        "        # Rule 3: If good mix of intermediate vocabulary → Intermediate\n",
        "        if (intermediate_ratio > 0.20 or   # At least 20% intermediate words\n",
        "            (0.10 <= intermediate_ratio <= 0.30 and  # Or balanced mix\n",
        "             basic_ratio > 0.4 and\n",
        "             advanced_ratio < 0.08)):\n",
        "            return \"intermediate\"\n",
        "\n",
        "        # Rule 4: Default based on sentence complexity\n",
        "        if avg_sentence_length > 18:\n",
        "            return \"advanced\"\n",
        "        elif avg_sentence_length > 12:\n",
        "            return \"intermediate\"\n",
        "        else:\n",
        "            return \"elementary\"\n",
        "\n",
        "# TEST WITH SPECIFIC INTERMEDIATE EXAMPLES\n",
        "classifier = BalancedClassifier('cefrj-vocabulary-profile-1.5.csv')\n",
        "\n",
        "# Clear intermediate examples that should work\n",
        "intermediate_texts = [\n",
        "    # Business/Work\n",
        "    \"The management team decided to implement new procedures to increase productivity. Employees will receive training sessions next week.\",\n",
        "\n",
        "    # Technology\n",
        "    \"Many people use smartphones for daily tasks like banking and shopping. App developers need to ensure their products are secure and user-friendly.\",\n",
        "\n",
        "    # Education\n",
        "    \"Students should develop good study habits to achieve academic success. Regular review of course material helps with long-term retention.\",\n",
        "\n",
        "    # Health/Lifestyle\n",
        "    \"Regular physical activity and a balanced diet contribute to overall wellbeing. Healthcare professionals recommend preventive checkups.\",\n",
        "\n",
        "    # Travel\n",
        "    \"When planning international travel, it's important to check visa requirements and vaccination recommendations. Travel insurance provides additional protection.\",\n",
        "\n",
        "    # Environment\n",
        "    \"Recycling programs help communities reduce waste and protect natural resources. Many cities now offer separate collection for different materials.\"\n",
        "]\n",
        "\n",
        "# Elementary examples\n",
        "elementary_texts = [\n",
        "    \"I like my school. My friends are nice. We play games together.\",\n",
        "    \"She works in a shop. She helps customers. They buy things.\",\n",
        "    \"The sun is hot. We go to the beach. We swim in the water.\",\n",
        "    \"My family eats dinner together. We talk about our day.\",\n",
        "    \"I have a red bike. I ride it in the park.\"\n",
        "]\n",
        "\n",
        "# Advanced examples\n",
        "advanced_texts = [\n",
        "    \"The epistemological ramifications of quantum entanglement challenge conventional ontological frameworks.\",\n",
        "    \"Contemporary geopolitical dynamics necessitate multilateral diplomatic engagement.\",\n",
        "    \"Neuroplasticity research elucidates the cerebral cortex's adaptive capabilities.\"\n",
        "]\n",
        "\n"
      ],
      "metadata": {
        "id": "1tYe3W5D9CYh"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# First, let me run your existing code to set up the classifier\n",
        "import re\n",
        "import pandas as pd\n",
        "from textstat import flesch_reading_ease\n",
        "\n",
        "class BalancedClassifier:\n",
        "    def __init__(self, vocab_file):\n",
        "        self.vocab_df = pd.read_csv(vocab_file)\n",
        "        self.vocab_levels = dict(zip(\n",
        "            self.vocab_df['headword'].str.lower(),\n",
        "            self.vocab_df['CEFR']\n",
        "        ))\n",
        "\n",
        "    def classify(self, text):\n",
        "        \"\"\"Simple but effective classification\"\"\"\n",
        "        if not text.strip() or len(text.split()) < 8:\n",
        "            return \"elementary\"\n",
        "\n",
        "        # Get basic features\n",
        "        words = re.findall(r'\\b[a-z]+\\b', text.lower())\n",
        "        sentences = [s.strip() for s in re.split(r'[.!?]+', text) if s.strip()]\n",
        "\n",
        "        if not words or not sentences:\n",
        "            return \"elementary\"\n",
        "\n",
        "        # Calculate key metrics\n",
        "        avg_sentence_length = len(words) / len(sentences)\n",
        "        readability = flesch_reading_ease(text)\n",
        "\n",
        "        # Vocabulary analysis - focus on B1/B2 words\n",
        "        intermediate_words = 0\n",
        "        advanced_words = 0\n",
        "        basic_words = 0\n",
        "\n",
        "        for word in words:\n",
        "            if word in self.vocab_levels:\n",
        "                level = self.vocab_levels[word]\n",
        "                if level in ['A1', 'A2']:\n",
        "                    basic_words += 1\n",
        "                elif level in ['B1', 'B2']:\n",
        "                    intermediate_words += 1\n",
        "                else:  # C1, C2\n",
        "                    advanced_words += 1\n",
        "\n",
        "        total_known_words = basic_words + intermediate_words + advanced_words\n",
        "        if total_known_words == 0:\n",
        "            return \"elementary\"\n",
        "\n",
        "        intermediate_ratio = intermediate_words / len(words)\n",
        "        advanced_ratio = advanced_words / len(words)\n",
        "        basic_ratio = basic_words / len(words)\n",
        "\n",
        "        # DECISION TREE - Much simpler logic\n",
        "        # Rule 1: If lots of advanced words → Advanced\n",
        "        if advanced_ratio > 0.15:  # More than 15% advanced words\n",
        "            return \"advanced\"\n",
        "\n",
        "        # Rule 2: If very simple vocabulary and structure → Elementary\n",
        "        if (basic_ratio > 0.8 and          # 80%+ basic words\n",
        "            avg_sentence_length < 12 and   # Short sentences\n",
        "            readability > 70):             # Very easy to read\n",
        "            return \"elementary\"\n",
        "\n",
        "        # Rule 3: If good mix of intermediate vocabulary → Intermediate\n",
        "        if (intermediate_ratio > 0.20 or   # At least 20% intermediate words\n",
        "            (0.10 <= intermediate_ratio <= 0.30 and  # Or balanced mix\n",
        "             basic_ratio > 0.4 and\n",
        "             advanced_ratio < 0.08)):\n",
        "            return \"intermediate\"\n",
        "\n",
        "        # Rule 4: Default based on sentence complexity\n",
        "        if avg_sentence_length > 18:\n",
        "            return \"advanced\"\n",
        "        elif avg_sentence_length > 12:\n",
        "            return \"intermediate\"\n",
        "        else:\n",
        "            return \"elementary\"\n",
        "\n",
        "# Initialize the classifier\n",
        "classifier = BalancedClassifier('cefrj-vocabulary-profile-1.5.csv')\n",
        "\n",
        "# Now let me test with some input text\n",
        "input_text = \"\"\"\n",
        "Recent advancements in quantum information science have precipitated a paradigm\n",
        "shift in computational cryptography, with researchers demonstrating scalable fault-tolerant\n",
        "qubits capable of executing Shor’s algorithm on classically intractable integer factorization\n",
        "problems. These developments exacerbate the vulnerability of widely deployed asymmetric encryption\n",
        "schemes, such as RSA and ECC, necessitating the accelerated deployment of post-quantum\n",
        "cryptographic protocols predicated on lattice-based, hash-based, and multivariate polynomial\n",
        "frameworks. Concurrently, the integration of topological qubits and error-correcting surface\n",
        " codes promises unprecedented coherence times, albeit with substantial engineering and material\n",
        " science challenges. Experts caution that without immediate interdisciplinary collaboration\n",
        "  among physicists, mathematicians, and cybersecurity professionals, the impending quantum era\n",
        "   could render existing digital security infrastructures obsolescent, thereby\n",
        "imperiling sensitive financial, governmental, and personal data at a global scale.\"\"\"\n",
        "\n",
        "# Classify the input text\n",
        "level = classifier.classify(input_text)\n",
        "\n",
        "print(\"INPUT TEXT CLASSIFICATION\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Text: {input_text}\")\n",
        "print(f\"Classification: {level.upper()}\")\n",
        "print(\"=\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c74klODmOw4S",
        "outputId": "e9b47a64-cda3-42be-a303-19479697d44e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INPUT TEXT CLASSIFICATION\n",
            "==================================================\n",
            "Text: \n",
            "Recent advancements in quantum information science have precipitated a paradigm \n",
            "shift in computational cryptography, with researchers demonstrating scalable fault-tolerant \n",
            "qubits capable of executing Shor’s algorithm on classically intractable integer factorization \n",
            "problems. These developments exacerbate the vulnerability of widely deployed asymmetric encryption \n",
            "schemes, such as RSA and ECC, necessitating the accelerated deployment of post-quantum \n",
            "cryptographic protocols predicated on lattice-based, hash-based, and multivariate polynomial \n",
            "frameworks. Concurrently, the integration of topological qubits and error-correcting surface\n",
            " codes promises unprecedented coherence times, albeit with substantial engineering and material \n",
            " science challenges. Experts caution that without immediate interdisciplinary collaboration\n",
            "  among physicists, mathematicians, and cybersecurity professionals, the impending quantum era\n",
            "   could render existing digital security infrastructures obsolescent, thereby \n",
            "imperiling sensitive financial, governmental, and personal data at a global scale.\n",
            "Classification: ADVANCED\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "15_EzgJsXZB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OHiLtmHXhzql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5yDnWyIAhzs5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XCvLslVPhzwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "# Assuming the following functions and variables are defined in previous cells:\n",
        "# - recommend_papers(user_query, tfidf_vectorizer, tfidf_matrix, df, N=5)\n",
        "# - tfidf_vectorizer, tfidf_matrix, df (from research paper recommender)\n",
        "# - predict_sentiment(text) (from sentiment analysis)\n",
        "# - classifier (from text difficulty classifier)\n",
        "# - classify_news_interface(news_text) (from news classification)\n",
        "\n",
        "def combined_interface(task, input_text):\n",
        "    \"\"\"\n",
        "    Combined Gradio interface function to handle different tasks.\n",
        "    \"\"\"\n",
        "    if task == \"Research Paper Recommendation\":\n",
        "        # Assuming N=5 for recommendation\n",
        "        recommended_papers = recommend_papers(input_text, tfidf_vectorizer, tfidf_matrix, df, N=5)\n",
        "        # Select relevant columns for display\n",
        "        display_columns = ['title', 'authors', 'summary', 'published_date']\n",
        "        return recommended_papers[display_columns], None, None\n",
        "    elif task == \"Sentiment Analysis\":\n",
        "        sentiment = predict_sentiment(input_text)\n",
        "        return None, sentiment, None\n",
        "    elif task == \"Text Difficulty Classification\":\n",
        "        level = classifier.classify(input_text).upper()\n",
        "        return None, None, level\n",
        "    # Add News Classification task\n",
        "    elif task == \"News Classification\":\n",
        "        category = classify_news_interface(input_text)\n",
        "        return None, None, None, category # Need to handle multiple outputs or restructure\n",
        "\n",
        "    return None, None, None\n",
        "\n",
        "# Create the Gradio interface\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# Unified Text Analysis Interface\")\n",
        "    with gr.Row():\n",
        "        task_selector = gr.Radio(\n",
        "            [\"Research Paper Recommendation\", \"Sentiment Analysis\", \"Text Difficulty Classification\", \"News Classification\"],\n",
        "            label=\"Select Task\"\n",
        "        )\n",
        "    with gr.Row():\n",
        "        text_input = gr.Textbox(label=\"Enter Input Text\")\n",
        "\n",
        "    # Define output components for each task\n",
        "    # Research Paper Recommendation output (DataFrame)\n",
        "    paper_output = gr.DataFrame(label=\"Recommended Papers\")\n",
        "    # Sentiment Analysis output (Textbox)\n",
        "    sentiment_output = gr.Textbox(label=\"Sentiment\")\n",
        "    # Text Difficulty Classification output (Textbox)\n",
        "    difficulty_output = gr.Textbox(label=\"Difficulty Level\")\n",
        "    # News Classification output (Textbox)\n",
        "    news_category_output = gr.Textbox(label=\"News Category\")\n",
        "\n",
        "\n",
        "    # Connect the inputs and outputs to the combined function\n",
        "    # Need to handle conditional outputs based on task selection\n",
        "    # A simple approach is to update all outputs and let Gradio handle visibility,\n",
        "    # or use gr.State and gr.Request to manage state and conditional updates.\n",
        "    # For simplicity here, we'll update all and rely on Gradio's default behavior\n",
        "    # or manual clearing if needed.\n",
        "\n",
        "    # Let's create separate functions for each task to make output handling clearer\n",
        "    def run_recommendation(query):\n",
        "        if query:\n",
        "             recommended_papers = recommend_papers(query, tfidf_vectorizer, tfidf_matrix, df, N=5)\n",
        "             display_columns = ['title', 'authors', 'summary', 'published_date']\n",
        "             return recommended_papers[display_columns]\n",
        "        return pd.DataFrame() # Return empty DataFrame if no query\n",
        "\n",
        "    def run_sentiment(text):\n",
        "        if text:\n",
        "            return predict_sentiment(text)\n",
        "        return \"\"\n",
        "\n",
        "    def run_difficulty(text):\n",
        "        if text:\n",
        "            return classifier.classify(text).upper()\n",
        "        return \"\"\n",
        "\n",
        "    def run_news_classification(text):\n",
        "        if text:\n",
        "            return classify_news_interface(text)\n",
        "        return \"\"\n",
        "\n",
        "\n",
        "    # Using gr.State to manage task selection and trigger updates\n",
        "    task_state = gr.State(None)\n",
        "\n",
        "    def update_task_state(task):\n",
        "        return task\n",
        "\n",
        "    task_selector.change(update_task_state, inputs=task_selector, outputs=task_state)\n",
        "\n",
        "    def process_input(task, input_text):\n",
        "        if task == \"Research Paper Recommendation\":\n",
        "            return run_recommendation(input_text), \"\", \"\", \"\"\n",
        "        elif task == \"Sentiment Analysis\":\n",
        "            return pd.DataFrame(), run_sentiment(input_text), \"\", \"\"\n",
        "        elif task == \"Text Difficulty Classification\":\n",
        "            return pd.DataFrame(), \"\", run_difficulty(input_text), \"\"\n",
        "        elif task == \"News Classification\":\n",
        "            return pd.DataFrame(), \"\", \"\", run_news_classification(input_text)\n",
        "        return pd.DataFrame(), \"\", \"\", \"\" # Default empty outputs\n",
        "\n",
        "    text_input.submit(\n",
        "        process_input,\n",
        "        inputs=[task_state, text_input],\n",
        "        outputs=[paper_output, sentiment_output, difficulty_output, news_category_output]\n",
        "    )\n",
        "\n",
        "    # Clear outputs when task changes\n",
        "    def clear_outputs():\n",
        "        return pd.DataFrame(), \"\", \"\", \"\"\n",
        "\n",
        "    task_selector.change(\n",
        "        clear_outputs,\n",
        "        inputs=None,\n",
        "        outputs=[paper_output, sentiment_output, difficulty_output, news_category_output],\n",
        "        queue=False # Don't queue this event\n",
        "    )\n",
        "\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 655
        },
        "id": "g9vexLNchzzX",
        "outputId": "963d2f4a-c91d-4f5a-b69d-8ae2ffd2c6ec"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://91e3fce29fe655ae35.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://91e3fce29fe655ae35.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0lto9gS4ktuw"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyNRRRqTm6bvPkBxtO0LZcqr",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "eee3f96f90614806ba04f8023de71a74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_49a3ca060e2e4b04b4e41c8789d116fd",
              "IPY_MODEL_b158454ecd5c4bd496eaa8bcbc468df7",
              "IPY_MODEL_c8405ac926154763ba0d869146a98de4"
            ],
            "layout": "IPY_MODEL_d86f6de623b945ea9b75f66850c38c64"
          }
        },
        "49a3ca060e2e4b04b4e41c8789d116fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_677d747ea1c54cffb097854ce67f8a2e",
            "placeholder": "​",
            "style": "IPY_MODEL_ad5a84a147784685a53ec320216d102b",
            "value": "README.md: "
          }
        },
        "b158454ecd5c4bd496eaa8bcbc468df7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bed0fe0787284e559a6064c14bdf7616",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7801ef4f7230452bbee3851df501c82d",
            "value": 1
          }
        },
        "c8405ac926154763ba0d869146a98de4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cbf65b552cdf4ae7a5b589b44586d4cd",
            "placeholder": "​",
            "style": "IPY_MODEL_c39001f0a6b347049f8e25cff6fde71d",
            "value": " 7.81k/? [00:00&lt;00:00, 383kB/s]"
          }
        },
        "d86f6de623b945ea9b75f66850c38c64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "677d747ea1c54cffb097854ce67f8a2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad5a84a147784685a53ec320216d102b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bed0fe0787284e559a6064c14bdf7616": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "7801ef4f7230452bbee3851df501c82d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cbf65b552cdf4ae7a5b589b44586d4cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c39001f0a6b347049f8e25cff6fde71d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c01f17ce01dd40dd90d3396affa1d513": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e17a314713594c14bc9487480b904c02",
              "IPY_MODEL_e095a4b592d8424f9c047b9fbc41705f",
              "IPY_MODEL_facdf5fecc484c06970be5755ec96db2"
            ],
            "layout": "IPY_MODEL_1ffdc8d1a9434f29857621a96425e87a"
          }
        },
        "e17a314713594c14bc9487480b904c02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa281fe7ffe341e09bda4bf22dd9af50",
            "placeholder": "​",
            "style": "IPY_MODEL_7ad5982588294a3098f35ba678c23a09",
            "value": "plain_text/train-00000-of-00001.parquet: 100%"
          }
        },
        "e095a4b592d8424f9c047b9fbc41705f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_041a50df4b6d4ed18fc0efa807e82ff1",
            "max": 20979968,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bbbd66e16d1748208442ad2675ab01fc",
            "value": 20979968
          }
        },
        "facdf5fecc484c06970be5755ec96db2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13213d6909f34d92b9d44c8abf70375d",
            "placeholder": "​",
            "style": "IPY_MODEL_0caa303ad06942ce96ba87c676b150da",
            "value": " 21.0M/21.0M [00:01&lt;00:00, 15.7MB/s]"
          }
        },
        "1ffdc8d1a9434f29857621a96425e87a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa281fe7ffe341e09bda4bf22dd9af50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ad5982588294a3098f35ba678c23a09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "041a50df4b6d4ed18fc0efa807e82ff1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbbd66e16d1748208442ad2675ab01fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "13213d6909f34d92b9d44c8abf70375d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0caa303ad06942ce96ba87c676b150da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e0cdfbe214047418b0ff6234f559dcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_397853e8d090459a9c2fe3e77fcf8d1b",
              "IPY_MODEL_9f2e02a4e28641c6977da46aa9b711ce",
              "IPY_MODEL_e4e16b6b7a9b453289db3103b8cfe022"
            ],
            "layout": "IPY_MODEL_15c329fec70346a5bd5e4f93f70cfdc1"
          }
        },
        "397853e8d090459a9c2fe3e77fcf8d1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37c1e8d411294955920a3ef67503f508",
            "placeholder": "​",
            "style": "IPY_MODEL_d8a710ce9262490f806ecaeeb3acfff2",
            "value": "plain_text/test-00000-of-00001.parquet: 100%"
          }
        },
        "9f2e02a4e28641c6977da46aa9b711ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_abeddd281a774684a56f76a9be05e432",
            "max": 20470363,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_80a01e2ed89545379e43e93280b41780",
            "value": 20470363
          }
        },
        "e4e16b6b7a9b453289db3103b8cfe022": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18ebe72e101346e980b3e823592c8a9f",
            "placeholder": "​",
            "style": "IPY_MODEL_7d0f2be5158842cd838b5600cbd787b6",
            "value": " 20.5M/20.5M [00:00&lt;00:00, 69.2kB/s]"
          }
        },
        "15c329fec70346a5bd5e4f93f70cfdc1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37c1e8d411294955920a3ef67503f508": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8a710ce9262490f806ecaeeb3acfff2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "abeddd281a774684a56f76a9be05e432": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80a01e2ed89545379e43e93280b41780": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "18ebe72e101346e980b3e823592c8a9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d0f2be5158842cd838b5600cbd787b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "beb3c73e0f314d7bae0260bea0857a7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7fb1825dcfe94e09b98877852c94f8ca",
              "IPY_MODEL_b8b106cd1b67466889fe60950f14c50d",
              "IPY_MODEL_b1b9a36c88e74ae7adb36903f5c29e7a"
            ],
            "layout": "IPY_MODEL_c8391e7dce5c4e528e8ee9a5421b6717"
          }
        },
        "7fb1825dcfe94e09b98877852c94f8ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9218dc59f1984db5b3a51b431dbd1929",
            "placeholder": "​",
            "style": "IPY_MODEL_1d07511b7e1e45dda555b3539d6071ff",
            "value": "plain_text/unsupervised-00000-of-00001.p(…): 100%"
          }
        },
        "b8b106cd1b67466889fe60950f14c50d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1127c23fe9f42ee9d11713080449116",
            "max": 41996509,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_94404791b5e94d71850dd96dffa88608",
            "value": 41996509
          }
        },
        "b1b9a36c88e74ae7adb36903f5c29e7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e93366a5bc9643ed8e431c89e145522c",
            "placeholder": "​",
            "style": "IPY_MODEL_f8b5b9df6ba94cf5a5e7a6c3b5e09bd2",
            "value": " 42.0M/42.0M [00:00&lt;00:00, 32.6MB/s]"
          }
        },
        "c8391e7dce5c4e528e8ee9a5421b6717": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9218dc59f1984db5b3a51b431dbd1929": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d07511b7e1e45dda555b3539d6071ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1127c23fe9f42ee9d11713080449116": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94404791b5e94d71850dd96dffa88608": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e93366a5bc9643ed8e431c89e145522c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8b5b9df6ba94cf5a5e7a6c3b5e09bd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e9d2f7077b8c44cb92ff06ad1a621579": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0285425bb6154d29ad0df2963348f677",
              "IPY_MODEL_d8044a3d171a472194be04cff1bc6452",
              "IPY_MODEL_15ef8cab1e5a488787280b41b92f5eff"
            ],
            "layout": "IPY_MODEL_5627514a8be24fc78c0b069335080bc0"
          }
        },
        "0285425bb6154d29ad0df2963348f677": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b11dd745b9a242ab9718fd6f8f231ae4",
            "placeholder": "​",
            "style": "IPY_MODEL_58437fc54d2446dd98478e6812001abf",
            "value": "Generating train split: 100%"
          }
        },
        "d8044a3d171a472194be04cff1bc6452": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d54beff1584f4e66be4be4dd4f244630",
            "max": 25000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fdd67dc421804821b9eae71422af401b",
            "value": 25000
          }
        },
        "15ef8cab1e5a488787280b41b92f5eff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2337cc0c0f064715be8335ba33481577",
            "placeholder": "​",
            "style": "IPY_MODEL_6644cb20030b479e9e1a3d6db8befae5",
            "value": " 25000/25000 [00:00&lt;00:00, 48909.72 examples/s]"
          }
        },
        "5627514a8be24fc78c0b069335080bc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b11dd745b9a242ab9718fd6f8f231ae4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58437fc54d2446dd98478e6812001abf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d54beff1584f4e66be4be4dd4f244630": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdd67dc421804821b9eae71422af401b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2337cc0c0f064715be8335ba33481577": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6644cb20030b479e9e1a3d6db8befae5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61d52cba2e6947b2940a63865c3ea14e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ddc8354db73a4a17b004a59354b6bd93",
              "IPY_MODEL_33f021df80574c319b5f1a97a4835a04",
              "IPY_MODEL_9d5e5b3d23b548449dcbefab70efc0ea"
            ],
            "layout": "IPY_MODEL_e4005302e5b6485499a3af17d68927bd"
          }
        },
        "ddc8354db73a4a17b004a59354b6bd93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae833fc5adf840feb06276f8d98afe26",
            "placeholder": "​",
            "style": "IPY_MODEL_6b529adcf5374d3e840ace4a750d80d1",
            "value": "Generating test split: 100%"
          }
        },
        "33f021df80574c319b5f1a97a4835a04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_649badb850f547b6ba86ddd7d3874496",
            "max": 25000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6e80bd8525014fd8ba10a24e5554c0aa",
            "value": 25000
          }
        },
        "9d5e5b3d23b548449dcbefab70efc0ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c316c715fcfa49559d89dc52696c4873",
            "placeholder": "​",
            "style": "IPY_MODEL_050326db98ed4b1ea039cb5cb5cc4033",
            "value": " 25000/25000 [00:00&lt;00:00, 140446.30 examples/s]"
          }
        },
        "e4005302e5b6485499a3af17d68927bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae833fc5adf840feb06276f8d98afe26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b529adcf5374d3e840ace4a750d80d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "649badb850f547b6ba86ddd7d3874496": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e80bd8525014fd8ba10a24e5554c0aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c316c715fcfa49559d89dc52696c4873": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "050326db98ed4b1ea039cb5cb5cc4033": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3810e7f0fb1c4ac3b9efcadfcdbb6d80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ed2deb0413f04838ade5c9927c92dcd9",
              "IPY_MODEL_d6be8db52332424580d0cc3d93a39e25",
              "IPY_MODEL_d2c53bbc209c414fb0d8bd1e269ab6c5"
            ],
            "layout": "IPY_MODEL_0b02007d61fd4d0cb587ebc17ce78e73"
          }
        },
        "ed2deb0413f04838ade5c9927c92dcd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f8d943693494bdf9c88474987bb8545",
            "placeholder": "​",
            "style": "IPY_MODEL_eb37a9d6b80143548050a50132a3261f",
            "value": "Generating unsupervised split: 100%"
          }
        },
        "d6be8db52332424580d0cc3d93a39e25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55eaeba2f64e4faa989da46d88be83d6",
            "max": 50000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_120d00197d8d40218541705333cdb965",
            "value": 50000
          }
        },
        "d2c53bbc209c414fb0d8bd1e269ab6c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_208e616f888c408dbc6772eb639b61b8",
            "placeholder": "​",
            "style": "IPY_MODEL_daf2b26f75da42b1b63fafcff96c6cf7",
            "value": " 50000/50000 [00:00&lt;00:00, 102011.92 examples/s]"
          }
        },
        "0b02007d61fd4d0cb587ebc17ce78e73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f8d943693494bdf9c88474987bb8545": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb37a9d6b80143548050a50132a3261f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "55eaeba2f64e4faa989da46d88be83d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "120d00197d8d40218541705333cdb965": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "208e616f888c408dbc6772eb639b61b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "daf2b26f75da42b1b63fafcff96c6cf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}